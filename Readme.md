# **Deep Learning with PyTorch: Building a Generative Adversarial Network**

## **Introduction**

This project demonstrates the implementation of a Generative Adversarial Network (GAN) using PyTorch. GANs are a powerful class of neural networks used for unsupervised learning, capable of generating new data that resembles a given training set. This notebook walks through the process of building and training a GAN to generate handwritten digits similar to those in the MNIST dataset.

## **Key Features**

* **Generative Adversarial Network:** Implementation of a GAN from scratch.  
* **PyTorch:** Built using the popular deep learning framework, PyTorch.  
* **MNIST Dataset:** Trained on the classic MNIST dataset of handwritten digits.  
* **Deep Convolutional GAN (DCGAN):** The architecture is inspired by DCGAN principles for stable training.  
* **Modular Design:** The code is structured into clear, reusable components for the generator, discriminator, and training loop.

## **Model Architecture**

The GAN consists of two main components: a Generator and a Discriminator.

### **Generator**

The Generator's role is to create realistic images from random noise. It takes a latent space vector as input and upsamples it to produce an image.

* **Input:** A 64-dimensional noise vector.  
* **Architecture:** A series of transposed convolutional layers with batch normalization and ReLU activation functions. The final layer uses a Tanh activation to scale the output to the range \[-1, 1\].

### **Discriminator**

The Discriminator's job is to distinguish between real images from the dataset and fake images generated by the Generator.

* **Input:** A 28x28 grayscale image.  
* **Architecture:** A sequence of convolutional layers with batch normalization and LeakyReLU activation functions, followed by a flattening layer and a final linear layer to produce a single logit output.

## **Dataset**

The model is trained on the **MNIST dataset**, which consists of 60,000 training images of handwritten digits (0-9). The images are 28x28 pixels and grayscale.

**Transformations Applied:**

* Random rotations between \-20 and \+20 degrees.  
* Conversion to PyTorch tensors.

## **Training Process**

The Generator and Discriminator are trained in an adversarial manner. The training loop alternates between training the Discriminator and the Generator.

* **Discriminator Training:** The Discriminator is trained to correctly classify real and fake images. Its weights are updated to maximize the log-likelihood of correctly identifying real images as real and fake images as fake.  
* **Generator Training:** The Generator is trained to fool the Discriminator. Its weights are updated to maximize the log-likelihood of the Discriminator misclassifying the generated images as real.

**Optimization:**

* **Optimizer:** Adam optimizer is used for both networks.  
* **Learning Rate:** 0.0002  
* **Betas:** (0.5, 0.99)  
* **Loss Function:** Binary Cross-Entropy with Logits Loss.

## **Dependencies**

To run this notebook, you will need the following libraries:

* torch  
* torchvision  
* numpy  
* matplotlib  
* tqdm  
* torchsummary

## **Usage**

1. **Clone the repository.**  
2. **Install the required dependencies.**  
3. Set runtime environment as T4 GPU.  
4. **Run the Colab Notebook:** Open and run the cells in the Generative\_Adversarial\_Network.ipynb notebook to train the model and generate images.

## **Results**

After training for a sufficient number of epochs, the Generator will be able to produce realistic-looking handwritten digits. The notebook includes visualizations of the generated images at various stages of training to show the model's progress.